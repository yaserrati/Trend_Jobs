{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f41c4457",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4311550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c95d70d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>the salary may go beyond</th>\n",
       "      <th>there are additional conditions or footnotes</th>\n",
       "      <th>country</th>\n",
       "      <th>is_remote</th>\n",
       "      <th>Job_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Computer Science,Data quality,Genetics,Mathema...</td>\n",
       "      <td>Not-Specified</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ocorian</td>\n",
       "      <td>AML/CFT &amp; Data Analyst</td>\n",
       "      <td>Ebène, Mauritius</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Agile,Data management,Finance,Security,,</td>\n",
       "      <td>Not-Specified</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Mauritius</td>\n",
       "      <td>False</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cricut</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>South Jordan, UT, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>Agile,Architecture,AWS,Computer Science,Comput...</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bosch Group</td>\n",
       "      <td>Application Developer &amp; Data Analyst</td>\n",
       "      <td>Nonantola, Italy</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Engineering,Industrial,Oracle,Power BI,R,R&amp;D</td>\n",
       "      <td>Not-Specified</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Italy</td>\n",
       "      <td>False</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>Data Engineer Full time (Public Sector) USA</td>\n",
       "      <td>Arlington, VA, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Mid-level</td>\n",
       "      <td>108000.0</td>\n",
       "      <td>AWS,Azure,Computer Science,Consulting,Dataflow...</td>\n",
       "      <td>Flex hours,Flex vacation,Parental leave,Unlimi...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Company                                    Job Title   \n",
       "0              SGS                        Clinical Data Analyst  \\\n",
       "1          Ocorian                       AML/CFT & Data Analyst   \n",
       "2           Cricut                    Machine Learning Engineer   \n",
       "3      Bosch Group         Application Developer & Data Analyst   \n",
       "4  Publicis Groupe  Data Engineer Full time (Public Sector) USA   \n",
       "\n",
       "                          Location   Job Type Experience level    Salary   \n",
       "0    Richardson, TX, United States  Full Time      Entry-level   48000.0  \\\n",
       "1                 Ebène, Mauritius  Full Time      Entry-level   48000.0   \n",
       "2  South Jordan, UT, United States  Full Time    Not specified   90000.0   \n",
       "3                 Nonantola, Italy  Full Time      Entry-level   48000.0   \n",
       "4     Arlington, VA, United States  Full Time        Mid-level  108000.0   \n",
       "\n",
       "                          Requirment of the company    \n",
       "0  Computer Science,Data quality,Genetics,Mathema...  \\\n",
       "1           Agile,Data management,Finance,Security,,   \n",
       "2  Agile,Architecture,AWS,Computer Science,Comput...   \n",
       "3       Engineering,Industrial,Oracle,Power BI,R,R&D   \n",
       "4  AWS,Azure,Computer Science,Consulting,Dataflow...   \n",
       "\n",
       "                                          Facilities   \n",
       "0                                      Not-Specified  \\\n",
       "1                                      Not-Specified   \n",
       "2                                 Career development   \n",
       "3                                      Not-Specified   \n",
       "4  Flex hours,Flex vacation,Parental leave,Unlimi...   \n",
       "\n",
       "   the salary may go beyond  there are additional conditions or footnotes   \n",
       "0                      True                                          True  \\\n",
       "1                      True                                          True   \n",
       "2                      True                                          True   \n",
       "3                      True                                          True   \n",
       "4                      True                                         False   \n",
       "\n",
       "         country  is_remote  Job_category  \n",
       "0  United States      False  Data Science  \n",
       "1      Mauritius      False            AI  \n",
       "2  United States      False            AI  \n",
       "3          Italy      False  Data Science  \n",
       "4  United States      False            AI  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('job_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701f8ce0",
   "metadata": {},
   "source": [
    "Data Analyst\n",
    "Data Scientist\n",
    "Power BI Developer\n",
    "BI Analyst\n",
    "Data Engineer\n",
    "Data Project Management\n",
    "AWS Cloud Logistics\n",
    "Product Analytics\n",
    "Data Manager\n",
    "Business Intelligence\n",
    "Data Architect\n",
    "Data Developer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b657060d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Clinical Data Analyst',\n",
       " 'AML/CFT & Data Analyst',\n",
       " 'Machine Learning Engineer',\n",
       " 'Application Developer & Data Analyst',\n",
       " 'Data Engineer Full time (Public Sector) USA',\n",
       " 'Sr Staff Data Scientist - ATG',\n",
       " 'Vendor Management and Data Quality Lead',\n",
       " 'Intern (Business Intelligence Service Support)',\n",
       " 'Summer 2023 Data Engineering Intern',\n",
       " 'Principal Cloud Data Engineer (Prisma Access)',\n",
       " 'Data Scientist (TE-CRG-GLO-2023-19-GRAP)',\n",
       " 'Data Analyst - Revenue Optimizer',\n",
       " 'Graduate Power BI Developer',\n",
       " 'SAP Consultant - Product Data Management',\n",
       " 'PreMaster Programm - Data Analytics and Visualization',\n",
       " 'Staff Data Scientist - ATG',\n",
       " 'Senior Data Analyst - Sales',\n",
       " 'BI Analyst',\n",
       " 'Data Scientist | Insights (f/m/d) - GER, UK, NL, PL',\n",
       " 'Senior Data Analyst (Remote within EMEA)',\n",
       " 'Senior Data Engineer (Evergreen)',\n",
       " 'Data Management Scrum Master',\n",
       " 'Rotational Development Program - Artificial Intelligence and Machine Learning Trainee',\n",
       " 'Data Engineer Scientist',\n",
       " 'Data Scientist (Elasticsearch)',\n",
       " 'Data Engineer F/H',\n",
       " 'BI Developer',\n",
       " 'Data Scientist - Fraud Risk',\n",
       " 'QuintoAndar - Senior Data Analyst',\n",
       " 'ML Research Engineer',\n",
       " 'Principal Engineer, Data Project Management',\n",
       " 'Senior Data Engineer',\n",
       " '(Senior) Digital Analytics Engineer',\n",
       " 'Senior Software Engineer (Data Pipeline)',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Science Lead (Hybrid)',\n",
       " 'Business Intelligence Analyst',\n",
       " 'Lead Business Intelligence Analyst',\n",
       " 'Sr Data Engineer',\n",
       " 'Data Modeler',\n",
       " 'Data Engineer',\n",
       " 'VP, Actuarial Modeling and Data Management',\n",
       " 'Junior Data Science Engineer (m/w/x)',\n",
       " 'Healthcare Data Analyst',\n",
       " 'Data Scientist',\n",
       " 'Data Analyst | Marketing or Sales (f/m/d) - GER, UK, NL, PL',\n",
       " 'Business Intelligence Expert',\n",
       " 'Senior Data Analyst',\n",
       " 'Principle MLOps Engineer',\n",
       " 'Machine Learning Research Engineer, Generative AI',\n",
       " 'Data Analyst - Product Innovation',\n",
       " 'Lead Data Scientist',\n",
       " 'Data Product Owner',\n",
       " 'Bi Analyst Jr - 24170',\n",
       " 'HTML Developer',\n",
       " 'Business Intelligence Developer',\n",
       " 'Data Scientist, Marketing Analytics',\n",
       " 'Senior Manager - AML/CFT & Data Analyst',\n",
       " 'Senior Data Visualization Analyst',\n",
       " 'Senior Data Engineer (Remote)',\n",
       " 'Customer Data Engineer',\n",
       " 'Data Engineer- Data Platform',\n",
       " 'Digital Marketing Lead (ZibraAI)',\n",
       " 'Staff Data Scientist - Marketing',\n",
       " 'Senior Sales Business Intelligence Manager',\n",
       " 'Data Analyst, Customer Experience',\n",
       " 'ETAS Test Lead - Autonomous Driving Solutions',\n",
       " 'Sr. Data Engineer',\n",
       " 'Specialist Solutions Architect - MLOps',\n",
       " 'Data Scientist, Terminal',\n",
       " 'Data Analyst Intern',\n",
       " 'React Native Engineer - Mobile (Dubai)',\n",
       " 'Artificial Intelligence Lead | KPMG Futures',\n",
       " 'Jr. CRM Data Quality Specialist',\n",
       " 'Data Management Consultant Banking (f/d/m) Financial Services Data Platform FSDM',\n",
       " 'Director, Artificial Intelligence (AI)',\n",
       " 'Intermediate BI Developer',\n",
       " 'Senior Business Intelligence Analyst',\n",
       " 'Data Analyst',\n",
       " 'Staff Machine Learning Engineer',\n",
       " 'Data Analyst (Remote)',\n",
       " 'Lead Applied Data Scientist (Experience with Media Mix Modeling)',\n",
       " 'Data Engineer I',\n",
       " 'Cloud Database Analyst',\n",
       " 'Senior Machine Learning Engineer',\n",
       " 'Junior Data Analyst',\n",
       " 'Financial Data Analyst',\n",
       " 'Senior Consultant in Data science',\n",
       " 'Staff Clinical Data Manager # 3073',\n",
       " 'HR Data Analyst',\n",
       " 'Consultant in Data Science',\n",
       " 'Staff Engineer, Data Platform',\n",
       " 'Senior Data Scientist, Marketing Analytics',\n",
       " 'Director, IVA and AI Solutions - Professional Services Practice Lead',\n",
       " 'Lead Data Analyst(Marketing/Growth Analytics)',\n",
       " 'Data Analyst, Service Analytics',\n",
       " 'Amazon Robotics - Hardware Engineer Co-op (July-December 2023), Amazon Robotics',\n",
       " 'Senior/Staff Data Engineer',\n",
       " 'Data Product Manager',\n",
       " 'FSA (FinTech) - Quantitative Machine Learning Specialist & Software Developer',\n",
       " 'Data Engineer Analyst',\n",
       " 'Software Engineer (Data Pipeline)',\n",
       " 'Associate Data Scientist',\n",
       " 'Data Engineering Analyst',\n",
       " 'Talan Consulting \\x96 Consultant Senior/Manager \\x96 Data Strategy (H/F)',\n",
       " 'Enterprise Data Architect - 6 month Contract',\n",
       " 'Data Engineer II',\n",
       " 'Data Scientist/Machine Learning Engineer',\n",
       " 'Senior Data Scientist, Product',\n",
       " 'Senior Technical Support Engineer, DataSet',\n",
       " 'Finance Business Intelligence , Operations Finance',\n",
       " 'Staff Machine Learning Modeler, Financial Crimes',\n",
       " 'Data Engineer - Music',\n",
       " 'Data Manager',\n",
       " 'Salesforce Administrator/Data Specialist',\n",
       " 'Data Engineer (Starlink)',\n",
       " 'Data Engineer confirmé BI - BIG DATA',\n",
       " 'Director, Spark Technical Solutions',\n",
       " 'Middle Data Engineer (Healthcare domain)',\n",
       " 'Senior Data Analyst (Pricing)',\n",
       " 'People Analytics Data Visualization Senior Associate (Open to Remote)',\n",
       " 'Développeur Power BI - H/F',\n",
       " 'Product Manager - Experts & Artificial Intelligence',\n",
       " 'Group Manager Data Analytics India',\n",
       " 'Vice President Director, Data Scientist',\n",
       " 'Business Intelligence Analyst, AWS Cloud Logistics',\n",
       " 'Scientist/Senior Scientist, Machine Learning',\n",
       " 'Principal Site Reliability Engineer, Datastores (Hybrid)',\n",
       " 'Machine Learning Manager (Systems)',\n",
       " 'Consultant Data Engineer',\n",
       " 'Machine Learning Engineer L3',\n",
       " 'Data Analyst Coches.net',\n",
       " 'Senior Product Marketing Manager, Conversational Intelligence & AI Products',\n",
       " 'Graduate Data Analyst',\n",
       " 'Analytics Engineer',\n",
       " 'Specialist Solutions Architect - Data Engineering (Public Sector)',\n",
       " 'Senior Data Quality Assurance Specialist',\n",
       " 'Senior Site Reliability Engineer, Datastores (Hybrid)',\n",
       " 'Customer Success Junior ML Engineer, Onboarding Specialist',\n",
       " 'Senior Data Science Engineer',\n",
       " 'Digital Analytics Engineer',\n",
       " 'Senior Big Data Engineer',\n",
       " 'Senior Data Scientist, Marketing',\n",
       " 'Analytics Engineer Intern',\n",
       " 'Master Data Team Manager',\n",
       " 'Senior Data Engineer, Enterprise Engineering',\n",
       " 'Data Operations Associate',\n",
       " 'Staff ML Engineer (8627)',\n",
       " 'Specialist Architect : Big Data',\n",
       " 'Research Engineer in Multi Agent Path Finding for Mobile Robots (f/m/div.)',\n",
       " 'Product Marketing Manager, Data Engineering',\n",
       " 'CV/ML Engineer for 3D Virtual Humans - Remote Europe',\n",
       " 'Senior Data Engineer - Data Bricks',\n",
       " 'Director AI Science',\n",
       " 'Researcher- Business Intelligence',\n",
       " 'Machine Learning Research Scientist',\n",
       " 'Staff Database Reliability Engineer, Datastores',\n",
       " 'Senior Data Scientist - Viator, London, Oxford, UK Remote',\n",
       " 'Data Analyst (Bangkok Based, Relocation Provided)',\n",
       " 'Associate AI/ML Engineer',\n",
       " 'Azure Data Architect',\n",
       " 'Senior Applied Data Scientist',\n",
       " 'Senior Scientist, Decision Sciences',\n",
       " 'Data Operations & Insights Manager',\n",
       " 'Principal ML Engineer - AI Platform',\n",
       " 'Principal Product Marketing Manager, AI & Machine Learning',\n",
       " 'Technical Support Specialist (Robotics) - EU - Remote',\n",
       " 'Data Architect',\n",
       " 'Operations Data Analyst (Tableau)',\n",
       " 'Head of Applied AI/ML',\n",
       " 'Data Analytics Engineer',\n",
       " 'Software Engineer - Autonomy Metrics',\n",
       " 'Product Manager- Data Visualization & Analytics',\n",
       " 'Data Science in Product Design Engineering',\n",
       " 'Senior Director of Product - Machine Learning',\n",
       " 'Senior Data Analyst (Bangkok Based, Relocation Provided)',\n",
       " 'Operations Planner Data Management Technician',\n",
       " 'Senior Associate Data Engineering',\n",
       " 'Data Operations Client Onboarding',\n",
       " 'Machine Learning Research Scientist - Reinforcement Learning',\n",
       " 'Machine Learning Engineer, Generative AI',\n",
       " 'Data Management Internship',\n",
       " 'Sr Big Data Engineer',\n",
       " 'Consulting - Robotics Process Automation (RPA) Developer',\n",
       " 'Data Engineer with Databricks - Empower (remote/Costa Rica-based)',\n",
       " 'Databricks and Scala Engineer geospatial',\n",
       " 'Software Engineer, Data Platform',\n",
       " 'Senior Manager Data Engineering',\n",
       " 'Senior Data Engineer (P3949).',\n",
       " 'Junior Data Engineer Customer Analytics',\n",
       " 'Chief Engineer, Autonomy (R2020)',\n",
       " 'Senior Research Data Analyst',\n",
       " 'Sport data operator',\n",
       " 'Associate Director | Artificial Intelligence Lead | KPMG Futures',\n",
       " 'Research Scientist',\n",
       " 'Data Engineering Manager',\n",
       " 'Principal Engineer - Data Integrations',\n",
       " 'Python Engineer - Machine Learning Specialist (Remote)',\n",
       " 'Senior Applied Scientist - Document Intelligence',\n",
       " 'Data Analyst, Go Live',\n",
       " 'Senior Data Scientist (M/F)',\n",
       " 'Researcher/Senior Researcher \\x96 Natural Language Processing and Text Analytics',\n",
       " 'Data Analyst (Customer Service Industry, Mandarin Support)',\n",
       " 'Manager Data Strategy',\n",
       " 'Business Partner, Data Analysis',\n",
       " 'Data Engineer - Remote',\n",
       " 'Marketing Data Analyst',\n",
       " 'Post-Doctoral Fellow or Associate - Agronomy Data Scientist',\n",
       " 'Sr. Data Scientist',\n",
       " 'Researcher- Computer Vision',\n",
       " 'Data Science Lead',\n",
       " 'Senior Data Scientist, Product Analytics',\n",
       " 'Software Engineer - Machine Learning, Granica Screen',\n",
       " 'Data Engineer - Türkiye',\n",
       " 'SDE-III, Data Engineering',\n",
       " 'Oracle Data Modeler / PL/SQL - Data warehouse',\n",
       " 'Product Data Specialist (HW)',\n",
       " 'SparkCognition Director of Accounting - Controller',\n",
       " 'Senior Machine Learning Scientist (USA REMOTE)',\n",
       " 'Senior Data Scientist (P171).',\n",
       " 'Cloud Data Analyst Engineer (FinOps)',\n",
       " 'DataOps Engineer',\n",
       " 'Robotic Research Engineer - Mechatronics',\n",
       " 'Manager - Applied Data Scientist',\n",
       " '??·????/Business Intelligence Engineer, Japan Operations Finance',\n",
       " 'Senior Data Engineer - (Christchurch)',\n",
       " 'Senior Software Engineer - Data Architecture skills',\n",
       " 'BI Developer, Analytics',\n",
       " 'Supervisão de Business Intelligence (foco em mídia/comunicação)',\n",
       " 'Senior Manager, Perception Deep Learning',\n",
       " 'SME Consultant for Data Analytics',\n",
       " 'Senior Data Strategist',\n",
       " 'Data Analyst (Oslo-based)',\n",
       " 'Senior AI Engineer',\n",
       " 'SQL Data Engineers',\n",
       " 'Subsurface Data Manager',\n",
       " 'Senior Data Analyst with Python SQL - MS- Bangalore',\n",
       " 'Data Analyst Supply Chain Management (f/m/d)',\n",
       " 'Senior Data Quality Developer',\n",
       " 'Remote Intermediate Fullstack Engineer (AI Team)',\n",
       " 'iOS Engineer (Dubai)',\n",
       " 'Business Intelligence Data Strategist',\n",
       " 'Data Engineer Customer Analytics',\n",
       " 'Sr. BI Analyst',\n",
       " 'Data Scientist Generalist',\n",
       " 'Business Intelligence Analyst - Sales Operations',\n",
       " 'Senior Developer - Data Engineer (AWS/Python/Node)',\n",
       " 'Senior Data Scientist: NLP',\n",
       " 'Data Analyst (Allegro Pay)',\n",
       " 'Data Analyst (DEA)',\n",
       " 'AI Research Engineer',\n",
       " 'AI Research Scientist',\n",
       " 'Manager, Business Operations - Diagnostic Imaging and Laboratory',\n",
       " 'Data Science Consultant',\n",
       " 'Customer Master Data Analyst',\n",
       " 'Senior Data Quality Engineer',\n",
       " 'Senior Data Analyst - Hybrid',\n",
       " 'Computer Vision Researcher',\n",
       " 'Research Scientist - Machine Learning and Algorithms',\n",
       " 'Senior Applied Scientist',\n",
       " 'Tableau/BI Developer',\n",
       " 'Data Scientist (Real-time Ops)',\n",
       " 'Data Science/ Analytics Intern- Long Term',\n",
       " 'Master Data Management Plants (f/m/div.)',\n",
       " 'Coordinator of Data Operations',\n",
       " 'Data Science Team Lead',\n",
       " 'AI Programmer VR (UE)',\n",
       " 'Data Engineer (Python) - Payments',\n",
       " 'Master Data Management Plants (f/m/div.) (salary: ~81.000 EUR p.a.*)',\n",
       " 'Data Analyst Pleno',\n",
       " 'Research Engineer PEM Electrolyzer (f/m/div.)',\n",
       " 'Consulting - Data Engineer',\n",
       " 'Data Analyst Intern - Product Analytics',\n",
       " 'System Reliability Engineer (Big Data)',\n",
       " 'Enterprise Data Architect',\n",
       " 'TTGP Fleet Data Manager/Senior JICO',\n",
       " 'Senior Software Engineer - Data analytics',\n",
       " 'Staff Technical Product Manager, AI Platform and Solutions',\n",
       " 'Big Data Engineer - PySpark',\n",
       " 'Consultant / Sr Consultant - QA Data Engineer',\n",
       " 'Computational Biologist, Translational Science - Location Flexible',\n",
       " 'Lead Software Engineer, ML Infrastructure',\n",
       " 'Senior Insurance Data Scientist',\n",
       " 'Principal Engineer, Data Systems',\n",
       " 'Clinical Data Manager',\n",
       " 'Data Analyst I - Fraud',\n",
       " 'Senior Data Scientist, Operations',\n",
       " 'Software Engineer - Data Platform (Python, Cloud, Big Data)',\n",
       " 'Senior Cloud Data Analyst Engineer (FinOps)',\n",
       " 'Data Engineer - Bulgaria',\n",
       " 'Power BI Developer',\n",
       " 'Consultant, Data Analytics',\n",
       " 'Junior MLOps - Intern',\n",
       " 'Business Intelligence Internship (Summer 23/24)',\n",
       " 'Business Analyst (Tech/AI)',\n",
       " 'Senior Applied Scientist, Amazon',\n",
       " 'Specialist Solutions Architect - Data Engineering (Financial Services)',\n",
       " 'Data Scientist eBike Systems (f/m/div.)',\n",
       " 'Graduate Data Scientist',\n",
       " 'Robotics Engineer, Sensors',\n",
       " 'Contract: Data Infrastructure Engineer',\n",
       " 'AI/ML Modeling, Simulation and Analysis Engineer (Senior)',\n",
       " 'Cloud Data Engineer',\n",
       " 'Head of Data Science, Analytics and BI',\n",
       " 'Clinical Data Reporter',\n",
       " 'Staff+ Machine Learning Engineer - Generative AI',\n",
       " 'Especialista em Auditoria Interna - Data Analytics',\n",
       " 'Engineering Team Lead, Imaging Tech',\n",
       " 'Senior ML Engineer - NLP',\n",
       " 'Data Analyst (Aberdeen-based)',\n",
       " 'Principal Engineer, Data and Control Systems',\n",
       " 'Data Scientist (Pricing)',\n",
       " 'Head of AML Operations (m/f/d)',\n",
       " 'Data Engineer - 14072',\n",
       " 'Data Analyst (Reporting and Insights)',\n",
       " 'Sr. Manager (AI/ML)',\n",
       " 'Data Scientist, Decisions - Rider',\n",
       " 'Data Architect - SME',\n",
       " 'Senior SW Engineer (Machine Learning)',\n",
       " '(Global) Senior Research Scientist',\n",
       " 'Staff Data Scientist, Model Risk Management',\n",
       " 'Graduate Imaging Geophysicist',\n",
       " 'Architecte Plateforme Big Data / DevOps - F/H',\n",
       " 'Data Analyst - Retention',\n",
       " 'Lead Machine Learning Engineer',\n",
       " 'Data Developer',\n",
       " 'Data Analyst - Digital Marketing (all genders)',\n",
       " 'Android Engineer (Dubai)',\n",
       " 'Data Specialist - Governance',\n",
       " 'Senior Robotics Process Automation Developer',\n",
       " 'Technical Product Manager, Data Engineering',\n",
       " 'Sr. Data Developer (Remote), Experian Consumer Services',\n",
       " 'Senior Data Analyst with Python SQL - Bangalore',\n",
       " 'Manager, Measurement Innovation & Data Science',\n",
       " 'Cloud Data Architect',\n",
       " 'Business Intelligence Engineering Manager',\n",
       " 'DevOps Engineer (Dubai)',\n",
       " 'Data Analytics Internship (Summer 23/24)',\n",
       " 'Confirmed Data Analyst - Data Pro Supply',\n",
       " 'Senior Machine Learning Engineer (Modeling)',\n",
       " 'Stage: Robotics',\n",
       " 'Data Scientist / Data Analyst',\n",
       " 'Product Data Analyst sénior (h/f) en CDI à Paris',\n",
       " 'Data Analyst - Stage',\n",
       " 'Senior Analytics Engineer',\n",
       " 'Sr. Software Engineer, Data Engineering',\n",
       " 'Senior Machine Learning Engineer I',\n",
       " 'Data Engineer Sr.Software Engineer DX',\n",
       " 'Senior Staff Data Engineer',\n",
       " 'Natural Language Processing Intern',\n",
       " 'Senior Data Engineers',\n",
       " 'Coordinateur projets Genotypage data analyse (H/F)',\n",
       " 'Machine Learning & Software Engineer, Infrastructure - US Remote',\n",
       " 'Customer-Facing Deep Learning Solutions Architect',\n",
       " 'Data Engineering Manager - Allegro Pay',\n",
       " 'Senior Business Intelligence Developer (Database Architect & ETL Developer)',\n",
       " 'Technical Mentor (Independent Contractor) - Data Engineering Nanodegree (US Timezone)',\n",
       " 'Data Analyst, Business Optimisation',\n",
       " 'Machine Learning Force Fields Scientist (Materials Science)',\n",
       " 'Principal Machine Learning Engineer - ATG',\n",
       " 'Senior Associate Data Sciences',\n",
       " 'Senior Data Engineer (all genders) AI',\n",
       " 'Intermediate / Senior Fullstack Engineer (AI Team)',\n",
       " 'Data Quality Analyst - Stage',\n",
       " 'Senior Software Engineer - AI/ML team (.net + python)',\n",
       " 'Software Engineer, Data Platform, Data Management',\n",
       " 'Senior Machine Learning Engineer (Modeling), Financial Crimes Technology',\n",
       " 'Research Analyst',\n",
       " 'Backend / Data Engineers II, Cerebro',\n",
       " 'Junior Data Manager',\n",
       " 'Data Infrastructure Engineer',\n",
       " 'Backend Engineer (Dubai)',\n",
       " 'Senior Software Engineer I, Machine Learning, Retrieval Sciences',\n",
       " 'Sr. Staff Machine Learning Engineer',\n",
       " 'Staff Systems Engineer, Autonomy & Simulation',\n",
       " '[??-??&???] Senior, Data Analyst (Channel Analytics)',\n",
       " 'Senior Machine Learning Expert (on-site, Brussels / Belgium)',\n",
       " \"Spécialiste, intelligence d'affaires / Specialist, Business Intelligence\",\n",
       " 'Senior Product Manager | API & Data Products',\n",
       " 'Senior Analyst, Data Science and Analytics',\n",
       " 'Senior Product Manager - Data Management & Search',\n",
       " 'Accounting Professor- Data Analytics/AIS- 90K+ Salary',\n",
       " 'Senior Data Engineer - Healthgrades',\n",
       " 'Sr Applied Data Scientist',\n",
       " 'Business Intelligence Engineer',\n",
       " 'Assistant Mgr - Data Sciences',\n",
       " \"Data Analyst - Stage de fin d'études - Paris 2e\",\n",
       " 'Trading BI Developer',\n",
       " 'Data Analytics Intern - Le Cubs 2023',\n",
       " 'Product Data Analyst -  F/H',\n",
       " 'Data Scientist (Crypto)',\n",
       " '[Job- 10639] Senior Data Engineer Developer, Brazil',\n",
       " 'Business Intelligence Associate',\n",
       " 'Analyst, Reporting and Business Intelligence',\n",
       " 'Data Science Software Engineer',\n",
       " 'Product Owner with Tableau/Power BI(6 to 10 years)',\n",
       " 'Machine Learning & Software Engineer, Infrastructure - EMEA Remote',\n",
       " 'Sr AI Solution Developer (ServiceNow Developer)',\n",
       " 'Data Integrations Engineer',\n",
       " 'Lead Software Engineer - AI/ML team (.net + python)',\n",
       " 'Transportation Data Analyst Coordinator',\n",
       " 'Senior Applied Data Scientist (all genders) AI',\n",
       " 'Power BI Analyst',\n",
       " 'Senior Cloud DevOps Engineer (Data & AI) bei eBike Systems (w/m/div.)',\n",
       " 'Business Intelligence Analyst I',\n",
       " 'Power BI Data Visualization Analyst',\n",
       " 'Data Analyst (CEO Office)',\n",
       " 'Senior Data Science Analyst- Model Validation',\n",
       " 'Sr. Revenue Operations Specialist - Data Analytics',\n",
       " 'PhD Position - Neuro-Symbolic AI for Scene Understanding in Autonomous Driving',\n",
       " 'Staff Data Analyst, Product Analytics',\n",
       " 'Senior Product Manager, Large Language Model',\n",
       " 'QuintoAndar - Analytics Engineer',\n",
       " 'VP, Data Products',\n",
       " 'Data Science Director, Adoption & Enterprise',\n",
       " 'Data Platform Developer, Machine Learning',\n",
       " 'Senior Vision Engineer (English version)',\n",
       " 'Lead Data Scientist (P3436)',\n",
       " '(Canada) Business Intelligence Engineer',\n",
       " 'Lead ML Platform Engineer',\n",
       " 'Staff Data Engineer',\n",
       " 'Transportation Data Analyst (Tableau)',\n",
       " 'Robotics Software Developer Intern Fall 2023',\n",
       " 'Senior Data Architect',\n",
       " 'Software Engineer, Computer Vision Program',\n",
       " 'Data Engineer - Tempcover',\n",
       " 'ML PhD Intern - LLMs & Generative AI',\n",
       " 'Alternance - « Data Analyst » ou « Equipe Business Intelligence » (H/F)',\n",
       " 'Software Engineer - Structured Data Strategies',\n",
       " 'Data Science Intern',\n",
       " 'Institution Data Analyst',\n",
       " 'Senior Solutions Engineer - Big Data',\n",
       " 'Principal Machine Learning (ML) Engineer',\n",
       " 'Product Data Engineer',\n",
       " \"Data Engineer - Stage de fin d'études - Paris 2e\",\n",
       " 'Senior Data Engineer/Scientist',\n",
       " 'Principal Data Scientist, Machine Learning',\n",
       " 'Sr Director - Project Implementation - Medical Imaging / PACS',\n",
       " 'Big Data BI Engineer',\n",
       " 'Principal Data Scientist (Spain, full-remote)',\n",
       " 'AI Programmer',\n",
       " 'Business Intelligence Data Analyst',\n",
       " 'Machine Learning for Natural Language Processing Intern',\n",
       " 'Data Scientist engineer',\n",
       " 'ML Postdoc Researcher - LLMs & Generative AI',\n",
       " 'Principal Engineer, Data Management Engineering',\n",
       " 'Lead Data Scientist - Pricing',\n",
       " 'Data Scientist, Product Analytics',\n",
       " 'Senior Infrastructure Software Engineer, ML Platform',\n",
       " 'Alumio Solution Engineer (Data Integration)',\n",
       " 'Senior AI Research Scientist \\x96 Perception and Machine Learning',\n",
       " 'Field Sample Specialist (Air Samples) - Eurofins Environment Testing \\x96 Pueblo, CO',\n",
       " 'Senior Research Scientist \\x96 AI-based Planning for Autonomous Systems',\n",
       " 'Internship: Business Intelligence and Finance Excellence',\n",
       " 'Senior Data Engineer, PHP',\n",
       " 'Head of Data Science & Predictive Modeling',\n",
       " 'Business and Commercial Banking (BCB) Business Intelligence and Analytics Graduate Programme - Gauteng',\n",
       " 'Data Scientist - Data Analytics and Infrastructure',\n",
       " '(Senior) Machine Learning Engineer - MLOps',\n",
       " 'Team Lead Data Science (f/m/x)',\n",
       " 'Senior Data Scientist - Monetization',\n",
       " 'Lead Machine Learning Research Engineer, Generative AI',\n",
       " 'Course Associate, Data Analysis and Visualization in Sustainability (Fall 2023)',\n",
       " 'Robotics Engineer',\n",
       " 'Ingénieur Data Modeler et/ou Tech Data - F/H',\n",
       " 'Biomedical Data Scientist',\n",
       " 'Product Analyst - Remote (Mumbai)',\n",
       " 'Databricks Administrator',\n",
       " 'Analyst, Data Engineering',\n",
       " 'Lead Data Engineer- Bangalore',\n",
       " 'Marketing Data Scientist',\n",
       " 'Insight Analyst',\n",
       " 'Data Analyst Junior F/H',\n",
       " 'Senior Applied Scientist I',\n",
       " 'Data Manager Consultant',\n",
       " 'Foundation Models Lead',\n",
       " 'Consultant Big Data & Machine Learning',\n",
       " 'Senior Machine Learning Scientist (8304)',\n",
       " 'Senior Product Manager (AI team)',\n",
       " 'Principal Applied Scientist',\n",
       " 'Director of Data Science',\n",
       " 'Data Analyst Consultant',\n",
       " 'Senior Market Research Analyst',\n",
       " 'Senior Manager of Master Data Management (Hybrid)',\n",
       " 'Mid Data Scientist (f/m/x), Remote (EU) / Berlin',\n",
       " 'Sr. Product Manager (AI team)',\n",
       " 'Data Analyst (Pricing)',\n",
       " 'Principal Data Strategist Consultant',\n",
       " 'Senior Vehicle Data Analyst',\n",
       " 'Machine Learning Engineer (m/w/x)',\n",
       " 'Principal Engineer, Datacenter Software Systems',\n",
       " 'Business Intelligence (Qlik) Developer',\n",
       " 'Staff Data Scientist, Credit Card',\n",
       " 'Head of Product Data Science',\n",
       " \"Data Engineer / Data Analyst - Stage de fin d'études - Paris 2e (H/F)\",\n",
       " 'Junior Data Engineer',\n",
       " 'Machine Learning Research Engineer - Federal',\n",
       " 'Lead Data Engineer (P3796)',\n",
       " 'Senior ML Engineer',\n",
       " 'BI Engineer & Data Visualisation',\n",
       " 'Senior Machine Learning Engineer (8031)',\n",
       " 'Python Machine Learning Engineer (AdLight)',\n",
       " 'Research Engineer in Text Analytics (Direct Contract with Bosch)',\n",
       " 'Consultant(e) Data Scientist / Recherche Opérationnelle',\n",
       " 'Sr. Quantitative Research Analyst',\n",
       " 'Senior Data Manager',\n",
       " 'Staff Infrastructure Software Engineer, ML Platform',\n",
       " 'Data Engineer (AWS)',\n",
       " 'Data Engineer - Veeva Link',\n",
       " 'Senior Data Engineer (8307)',\n",
       " '(Mid level) Business Intelligence Analyst SCM (f/m/x)',\n",
       " \"Data Analyst - Stage de fin d'études - Paris 2e (H/F)\",\n",
       " 'Senior AI Programmer',\n",
       " 'AI Research Scientist \\x96 Perception and Machine Learning',\n",
       " 'Data Engineer 2',\n",
       " 'Scientist/Sr. Scientist, Computational Biology',\n",
       " 'Data Scientist Consultant',\n",
       " 'Manager, Data Engineering',\n",
       " 'Consultant | Data Analyst | KPMG Futures',\n",
       " 'Research Scientist \\x96 AI-based Planning for Autonomous Systems',\n",
       " 'Financial Data Analyst (m/f/d)',\n",
       " 'Analyst - Organizational Effectiveness (Data Management & Modelling, M&A)',\n",
       " 'Data Architect - Talent Pipeline',\n",
       " 'Data Analytics Hub Manager',\n",
       " 'Manager, Business Intelligence',\n",
       " 'Senior Data Analyst, Marketing & Enrollment - Hybrid',\n",
       " 'Architecte DATA - Décisionnel et Entrepôt Données Santé - Data Architect',\n",
       " 'Middle Product Manager (Data Analysis, Fintech)',\n",
       " 'Director, Data Science',\n",
       " 'Principal Machine Learning Engineer',\n",
       " 'Imaging Geophysicist - CDI permanent contract',\n",
       " 'Junior Business Intelligence Analyst',\n",
       " 'Lead Data Analyst',\n",
       " 'Senior Technical Integration Consultant- MFT, Migrations, ETL Experience- US Based Remote',\n",
       " 'Senior Data Analyst (Flights team, Bangkok-based, Relocation provided)',\n",
       " 'Data Engineer, Operations (AdScribe)',\n",
       " 'Lead BI Analyst (Supply Analytics, Bangkok-based)',\n",
       " 'Sr. Cloud & Data Engineer (Hybrid)',\n",
       " 'Instructor- Data Analytics',\n",
       " 'Data Analyst (Procurement)',\n",
       " 'Technical Program Manager, Artificial Intelligence & Data',\n",
       " 'Staff Machine Learning Platform Engineer',\n",
       " 'Junior Data and Insight Analyst',\n",
       " 'Business Intelligence Manager',\n",
       " 'Data Enginner',\n",
       " 'Monetization Data Analyst, Marketing Analytics',\n",
       " 'Principal Software Engineer, Applied ML',\n",
       " 'Azure Data Engineer',\n",
       " 'Electrical Design Engineer, Data Center Design Engineering',\n",
       " 'AI Architect, IT',\n",
       " 'Data Science Intern - Large Language Models',\n",
       " 'Deployment Specialist -(Travel, Early Career Robotics)-Central to East Coast - US',\n",
       " 'Staff Software Engineer, Machine Learning Acceleration',\n",
       " 'Senior BI Developer',\n",
       " 'Senior Data Engineer, Data Engineering',\n",
       " 'Product Data Specialist',\n",
       " 'Data Manager Zakelijke Markt',\n",
       " 'Business Intelligence Specialist',\n",
       " 'Consultant(e) Data Science - Bureau de Lyon',\n",
       " 'Associate Director, Data Engineering',\n",
       " 'Consultant(e) Senior Data Science',\n",
       " 'Consultant(e) Data Science - Bureau de Marseille',\n",
       " 'Staff Data Scientist, Business - Sales & Customer Success',\n",
       " 'Copywriter (ZibraAI)',\n",
       " 'Senior Product Manager, Data Infrastructure',\n",
       " 'Data Analyst (Flights team, Bangkok-based, Relocation provided)',\n",
       " 'Senior Data Scientist- Creator Content',\n",
       " 'Staff Data Scientist',\n",
       " 'Data Engineer - H/F',\n",
       " 'Senior Software Engineer (Power BI) -ELECTION-46',\n",
       " 'US Master Data Manager',\n",
       " 'Consultant(e) Senior Data Science - Bureau de Marseille',\n",
       " 'Data Analyst F/H',\n",
       " 'Senior Business Intelligence Analyst (Bangkok-based, Relocation provided)',\n",
       " 'Instructor, AI/Machine Learning (Part-time)',\n",
       " 'Big Data Engineer (Spark/ Hadoop/ Scala)',\n",
       " 'Staff Software Engineer, Machine Learning Infrastructure',\n",
       " 'Wind Master Data Manager',\n",
       " 'Senior Applied Scientist II',\n",
       " 'Data Science Analyst',\n",
       " 'Machine Learning Engineer - LLM',\n",
       " 'Product Data Analyst - Gaming Analytics',\n",
       " 'Consultant(e) Senior Data Science - Bureau de Nantes',\n",
       " 'Chatbot Engineer',\n",
       " 'Machine Learning Scientist (L6) - Product',\n",
       " 'Imaging Coordinator',\n",
       " 'People Analytics Senior Data Analyst (Remote)',\n",
       " 'Information Security & Data Management Trainer',\n",
       " 'Senior Machine Learning Modeler, Financial Crimes',\n",
       " 'Lead Analyst (BI Data Development)',\n",
       " 'Principal Machine Learning Engineer - Personalization',\n",
       " 'Staff Software Engineer, Data Platform',\n",
       " 'Consultant(e) Data Science',\n",
       " 'Senior Insight Analyst - Digital Experience',\n",
       " 'Alternance Consultant(e) Data Analytics - H/F',\n",
       " 'Consultant(e) Data Science - Bureau de Nantes',\n",
       " '302 - Data Analytics Specialist - CMS End Stage Renal Disease (ESRD)',\n",
       " 'Senior Software Engineer - Data Visualization',\n",
       " 'Senior MLOps Engineer',\n",
       " 'Senior ML Engineer (Remote)',\n",
       " 'Research Engineer - Research',\n",
       " 'Principal Software Engineer, Data Engineering',\n",
       " 'Product Owner - Data Visualization Specialist and Quality',\n",
       " 'Data Engineer Senior - DataOps / AWS / Archi Distribuée (f/m/x)',\n",
       " 'Senior AI Data Engineer (USA REMOTE)',\n",
       " 'Principal Machine Learning Engineer- Economy',\n",
       " 'Data Quality Management Specialist',\n",
       " 'Machine Learning Implementation Engineer',\n",
       " 'Robotics Software Engineer',\n",
       " 'Data Management System General Support Coordinator, Consultancy',\n",
       " 'Senior Data Scientist (Deep Learning Specialist)',\n",
       " 'Machine Learning Engineer / Senior Machine Learning Engineer',\n",
       " 'Managing Director, Data Engineering, Reporting, Visualization',\n",
       " 'Principal Deep Learning Engineer - Computer Vision',\n",
       " 'Data Engineer - Team Data Platform (f/m/x)',\n",
       " 'BI Developer (SAP BO & Qlik)',\n",
       " 'Technical Director, Machine Learning (Individual Contributor)',\n",
       " 'Senior Analyst, Data Science (R-14532)',\n",
       " 'Sr. ML Engineer (Infrastructure)',\n",
       " 'Data Analyst II',\n",
       " 'Director, Business Intelligence',\n",
       " 'Senior Platform Data Engineer, People Analytics',\n",
       " 'Sr Machine Learning Engineer',\n",
       " 'Data Scientist (MMM)',\n",
       " 'Senior Spark Technical Solutions Engineer',\n",
       " 'Support Ops Manager I, ML Data Operations, FBA Support Operations',\n",
       " 'Head of Business Intelligence and Analytics',\n",
       " 'Senior Analyst - Business Intelligence (Bangkok-based, Relocation Provided)',\n",
       " 'Lead Data Developer',\n",
       " 'Program Manager, Operations Finance Business Intelligence, Japan Operations Finance',\n",
       " 'Engineering Manager, ChatGPT for Business',\n",
       " 'AI Data Engineering and Data Science Manager (USA REMOTE)',\n",
       " 'Consultant (German Speaking) - Data Analytics',\n",
       " 'Research Scientist, Responsible AI',\n",
       " 'Data Scientist, Generative AI',\n",
       " 'Data Analytics Manager',\n",
       " 'Data Engineer (Melbourne)',\n",
       " 'Sr. Product Designer - Data Management (UK)',\n",
       " 'NLP Engineer',\n",
       " '#659 Data Engineer',\n",
       " 'Specialist Solutions Architect - Data Engineering & Azure',\n",
       " 'Data Scientist Intern',\n",
       " 'People Data Analyst',\n",
       " 'Senior/ Lead Data analytics',\n",
       " 'Head of Health Data Science',\n",
       " 'Senior Data Scientist - Discovery Experiences',\n",
       " 'Data Engineer - NBC Sports Next',\n",
       " 'Senior Researcher (PostDoc) for Big Data Processing (m/f/x)',\n",
       " 'Applied Scientist II',\n",
       " 'Senior Data Scientist - Creator Success',\n",
       " 'Head of Data Science (f/m/x)',\n",
       " 'Director of Machine Learning Platform Engineering',\n",
       " 'Staff Research Scientist/Engineer',\n",
       " 'Data Analyst and BI Developer',\n",
       " 'Data Engineer Databricks',\n",
       " 'Senior Software Engineer (Data Engineering)',\n",
       " 'HRIS & Data Analytics Specialist',\n",
       " 'Group Manager, Technical Data Science',\n",
       " 'Expert Data Scientist (f/m/x)',\n",
       " 'Research Analyst (RPA Engineer)',\n",
       " 'Data Engineer, Clearing and Custody',\n",
       " 'Analytics Engineer - Analytics Hub',\n",
       " 'Internship - Data Analyst',\n",
       " 'Data Scientist, IPC - Specialized Selection',\n",
       " 'Prompt Engineering Internship',\n",
       " 'Partner Data Specialist',\n",
       " 'Azure Data Engineer (SQL/Python)',\n",
       " 'Analyste-Programmeur spécialiste ETL',\n",
       " 'Data Engineer, Creative Media Operations',\n",
       " 'Executive Training Coach, Artificial Intelligence',\n",
       " 'Adjunct Instructors - Data Science Program - 2023/2024',\n",
       " 'Senior SMWDC Data Analytics Team Lead',\n",
       " 'Senior Data Engineer I',\n",
       " 'Data Visualisation Consultant',\n",
       " 'Head of Data',\n",
       " 'Senior DataOps Engineer (kafka)',\n",
       " 'Stage Ingénieur Machine Learning (F/H)',\n",
       " 'Senior/Staff Machine Learning Engineer - Ecommerce Fraud Detection',\n",
       " 'Lead-Data Analyst',\n",
       " 'Senior Applied Scientist, Prime Video',\n",
       " 'Product Data Management Manager (Hybrid)',\n",
       " 'Data Scientist for Reliability Engineering (M/F/D)',\n",
       " 'Développeur ETL (H/F)',\n",
       " 'Power BI Engineer',\n",
       " 'Senior Backend Engineer, ML Research',\n",
       " 'Data Engineer - Remote (Req. #515)',\n",
       " 'VP Engineering - Machine Learning',\n",
       " 'Senior Product Manager, Automation & Machine Learning',\n",
       " 'Data Analyst (Remote | UK)',\n",
       " 'Director, Trust & Panel Data Integrity',\n",
       " 'Data Scientist (Data Science Hub)',\n",
       " 'Machine Learning Engineer Intern',\n",
       " 'Graduate Analytics Engineer',\n",
       " 'Business Intelligence Engineer, Advertising Trust Data',\n",
       " 'Senior Research Scientist',\n",
       " 'AI Solution Cluster Manager',\n",
       " 'Senior Battery Modeling Engineer, Data',\n",
       " 'Software Engineer \\x96 Model Inference',\n",
       " 'Backend Software Engineer, Data Engineering',\n",
       " 'Senior/Principal ML Engineer, Content Understanding',\n",
       " 'Delivery Solutions Architect : Big Data',\n",
       " 'Sr Data Product Manager - Trading Experience',\n",
       " 'Data Scientist, Poland',\n",
       " 'Staff Machine Learning Engineer (Modeling), Risk',\n",
       " 'HR ( Data Analyst)  - Junior Manager',\n",
       " 'Senior People Data Analyst - Workday',\n",
       " 'Logistics Lead - Imaging',\n",
       " 'Machine Learning Researcher (internship)',\n",
       " 'Function Developer - Artificial Intelligence/Machine Learning in Automobile Applications',\n",
       " 'Sr Research Analyst - LNG',\n",
       " 'Sr. Business Analyst, Digital Services Business Intelligence (DSBI)',\n",
       " 'Senior data analyst',\n",
       " 'Lead AI Programmer - Remote',\n",
       " 'Engineer (Mid- Data Engineer)',\n",
       " 'Data Scientist (Machine Learning Modelling)',\n",
       " '4295 Senior Data Analyst',\n",
       " 'Senior Manager (Project & Data Management)',\n",
       " 'Senior Spark Data Engineer',\n",
       " 'Pessoa Engenheira de Machine Learning Sênior',\n",
       " 'Senior Software Engineer, Data Platform - Remote',\n",
       " 'Senior Machine Learning Engineer- Price Freeze (100% remote)',\n",
       " '(Senior) Director Data Science for Pricing / Yield Management  (m/f/d)',\n",
       " 'Big Data Engineer \\x96 Hadoop',\n",
       " 'Senior Machine Learning Engineer - Search',\n",
       " 'Senior Associate Data Engineering L1',\n",
       " 'Big Data Infrastructure Engineer',\n",
       " '[Job- 10566] Senior Data Visualization Analyst, Brazil',\n",
       " 'Satellite Image Processing and AI Engineer',\n",
       " 'Data Engineer (Hybrid)',\n",
       " 'Lead/Principal Product Manager, AI/ML',\n",
       " 'Senior Data Engineer - Data Scientist  (f/m/div.)',\n",
       " 'Machine Learning / AI Engineer (Indonesia)',\n",
       " 'Lead Partner Commerce Analyst (Business Intelligence)',\n",
       " 'Senior Manager, Data Engineering',\n",
       " 'Junior Data Scientist',\n",
       " 'Data Engineer \\x96 Oracle',\n",
       " 'Data Analyst (S&OP)',\n",
       " 'Graduate Motorsport Data Analyse and Engineer',\n",
       " 'Data Operations Manager - Link',\n",
       " 'VP of Data Science',\n",
       " 'Manager, Data Science (Machine Learning)',\n",
       " 'Data Scientist IV',\n",
       " 'Data Science - Machine Learning Engineer',\n",
       " 'Principal Machine Learning Engineer (DLP)',\n",
       " 'Data Engineer I (BLD)',\n",
       " 'Senior Data Science Manager, Marketing',\n",
       " 'Scientist I, Computational Biology',\n",
       " 'Data Analytics Architect, Multi-Instance',\n",
       " 'Head of Data Ops & Render Support',\n",
       " 'Sr. Security Analytics Engineer',\n",
       " 'Senior DevOps Engineer \"Big Data Platform - Hadoop\" (f/m/div.)',\n",
       " 'Principal  - Data Science',\n",
       " 'Data Scientist, Product Growth',\n",
       " 'Principal Applied Scientist, Sponsored Products',\n",
       " 'Senior Machine Learning Architect',\n",
       " 'Credit Risk Decision Scientist - Afterpay',\n",
       " 'Python/ETL Developer',\n",
       " 'Business Intelligence Associate Manager(Client facing)',\n",
       " 'Business Intelligence MBA Associate',\n",
       " 'Data Scientist, Research',\n",
       " 'Vacation work - (AIS) Actuarial & Insurance Solutions 2023- Johannesburg',\n",
       " 'Applied Scientist- Search Query Recommendation, Search Assistance',\n",
       " 'Senior Robotics Software Engineer',\n",
       " 'Senior Product Manager, Supplier Advertising (Machine Learning)',\n",
       " 'Pessoa Engenheira de Machine Learning Júnior',\n",
       " 'Quantitative Research Analyst',\n",
       " 'Business Intelligence Engineer, Analytics',\n",
       " 'Gruppenleitung Supply Chain Management & Data Analytics (w/m/div.)',\n",
       " 'Staff Data Engineer (Spark, Python, Hadoop)',\n",
       " 'Data Architect (optional relocation to Montenegro)',\n",
       " 'Data Science Intern - Large Language Model',\n",
       " 'Staff Data Scientist - NLP',\n",
       " 'Senior ETL Datastage Developer',\n",
       " 'Data Analyst, Product',\n",
       " 'MLOps Engineer, LLM',\n",
       " 'Data Engineer - Data Warehousing (SQL/Python) REF1478Z-German Speaking',\n",
       " 'Senior Consultant - Azure Data Engineer',\n",
       " 'Director, Data Engineering',\n",
       " 'Business Intelligence Analytics Lead, (Permanent Remote)',\n",
       " 'Recruitment Data Analyst',\n",
       " 'Technical Leader of Computer Vision',\n",
       " 'AI Product Owner - Manufacturing (f/m/div.)',\n",
       " 'Stage - NLP Engineer (H/F)',\n",
       " 'Machine Learning Ops Specialist',\n",
       " 'Manager of Growth Data Science',\n",
       " 'Customer Success & Insight Analyst',\n",
       " 'Senior Product Manager - Machine Learning',\n",
       " 'Data Scientist (Customer Acquisition)',\n",
       " 'IT Data Engineer',\n",
       " 'Staff Research Scientist/Engineer - ATG',\n",
       " 'Analista de Sistemas | Foco em Power BI e SharePoint',\n",
       " 'Staff Applied Scientist (Open to remote across ANZ)',\n",
       " 'Manager, Product Data Analytics',\n",
       " 'Applied Scientist II, AWS AI',\n",
       " 'Senior Robotics Engineer',\n",
       " 'Scientist 1, Data Science',\n",
       " 'Research Engineering Manager, Unit 42 (Remote)',\n",
       " 'Act Two Program- Sr. Analyst, Data Quality',\n",
       " 'Software Engineer, Robotics',\n",
       " 'Staff Software Engineer - Streaming Data Pipelines',\n",
       " 'Sr. Data Engineer - (Java + Spark)',\n",
       " 'Associate Director, Business Intelligence',\n",
       " 'Senior Data Scientist - Retailer',\n",
       " 'Senior Data Scientist, Core',\n",
       " 'Senior/Lead Data Scientist',\n",
       " 'ESRD Data Analyst and Program/Technical Specialist (Contract Contingent)',\n",
       " 'AI/ML Data Labeling Manager - UK',\n",
       " 'Data Scientist (Job Ref:1823)',\n",
       " 'Data Analyst I',\n",
       " 'Staff Bioinformatics Scientist - Machine Learning/Classifier Research and Development #2802 (Seattle)',\n",
       " 'Consultant(e) Power BI',\n",
       " 'Data Engineer Specialist',\n",
       " 'Junior/Mid Data Analyst',\n",
       " 'Sr Staff Applied Research Scientist - ATG Core LLM Team',\n",
       " 'Senior Data Modeler',\n",
       " 'Data Engineer-Operations',\n",
       " 'Business/data analyst',\n",
       " 'Manager - DS-AI & Machine Learning',\n",
       " 'Senior Backend Software Engineer- Big Data Analytics',\n",
       " 'Staff Product Manager, Machine Learning and Recommendations',\n",
       " 'Bilingual Data Analyst',\n",
       " 'Senior Data Developer AWS Redshift',\n",
       " 'Analytics Engineer - Consumer & Order and Pay',\n",
       " 'Sr. Data Engineer (Remote)',\n",
       " 'Staff Machine Learning Engineer, Entity Understanding - NYC',\n",
       " '(Senior) Director Data Science for Pricing / Yield Management & Data Science Lead Team Portugal (m/f/d)',\n",
       " 'AI/ML Data Labeling Manager - US',\n",
       " 'Data Scientist (S&OP)',\n",
       " '[EA] AI Tech Lead (Artificial Intelligence)',\n",
       " 'Data Engineer - Data Platform',\n",
       " 'Finance Data Analyst',\n",
       " 'Sr SRE/DevOps Engineer (AI & Machine Learning)',\n",
       " 'Business Data Analyst - Dailymotion Advertising (All Genders)',\n",
       " 'Data Scientist - 4365',\n",
       " 'Data Engineer \\x96 Data Lake',\n",
       " 'Engineer- Data Engineer',\n",
       " 'PreMaster Programm - Big Data (Analytics)',\n",
       " 'Senior Software Engineer, Data Safety',\n",
       " 'Sr. Business Intelligence Analyst',\n",
       " 'Big Data Engineer (IT-DA-DS-2023-76-LD)',\n",
       " 'Staff Bioinformatics Scientist - Machine Learning/Classifier Research and Development #2802 (San Diego)',\n",
       " 'Senior Expert BigData & AI Public Cloud (m/w/d) - Open Telekom Cloud REF1768P',\n",
       " 'Lead Software Engineer, Machine Learning Platform',\n",
       " 'AI Engineer',\n",
       " 'Associate Director/Director of Chemical Data Analytics',\n",
       " 'Senior Data Engineer -REMOTE',\n",
       " 'Data Scientist Senior',\n",
       " 'Director | Master Data Management Delivery Lead| Data & Cloud - NV1 Clearance',\n",
       " 'Senior Data Analyst, International',\n",
       " 'Data Engineer Pleno',\n",
       " 'Data Engineer, Customer Experience and Business Trends',\n",
       " 'AI Compiler and Performance Engineer',\n",
       " '2023 POWER BI MSBI Developer BD/XAI COB',\n",
       " 'Staff Data Scientist, Strategic Planning & Forecasting',\n",
       " 'Big Data Specialist',\n",
       " 'Data Scientist (M/F)',\n",
       " 'Data Scientist (Mid Level)',\n",
       " 'Sr Staff DevOps - Terraform, Kubernetes, CI/CD, Spark / Kafka, Linux, Scripting',\n",
       " 'Staff Machine Learning Engineer - Ads',\n",
       " 'Engineer, Computer Vision',\n",
       " 'CNSP Surface Force Training Requirements & Data Analyst',\n",
       " 'ETL Developer - Remote (USC, GC, GC EAD)',\n",
       " 'Data Engineer (Hong Kong)',\n",
       " 'Senior Frontend Software Engineer, Machine Learning Infrastructure',\n",
       " 'Data Engineer with Top Secret',\n",
       " 'Senior Data Scientist (P3485)',\n",
       " 'Data & Analytics Engineer',\n",
       " 'Engineer, Computer Vision and Graphics',\n",
       " 'Senior Clinical Data Manager',\n",
       " 'ChatGPT & AI Consultant (Part Time)',\n",
       " 'Python AI Developer (Remote)',\n",
       " 'Senior Staff Software Engineer, Machine Learning',\n",
       " 'Senior Backend Engineer, Applied Machine Learning',\n",
       " 'Oracle Data Analyst',\n",
       " 'Staff Data Engineer (Snowflake / Kafka)',\n",
       " 'Data Scientist Intern (End of studies)',\n",
       " 'VP of Data Science and Analytics',\n",
       " 'Business Intelligence Analyst - Risk',\n",
       " 'Senior Scientist, Machine Learning',\n",
       " 'Graduate Data Engineer',\n",
       " 'Engineering Manager 1 - Data Engineering Developer Experience',\n",
       " 'Applied Scientist II, Amazon Search',\n",
       " 'Lead Engineer, MLOps Platform',\n",
       " 'Machine Learning Engineer - Simulation',\n",
       " 'Workplace Analytics Engineer',\n",
       " 'Machine Learning Intern/Co-op (Fall 2023)',\n",
       " 'Artificial Intelligence Software Library Technical Lead',\n",
       " 'Business Intelligence (BI) Engineer',\n",
       " 'NATOIS-0008 Data Scientist (NS) - TUE 13 Jun',\n",
       " 'Applied Research Scientist',\n",
       " 'Mid/Sr Machine Learning Engineer',\n",
       " 'Staff Software Engineer - Machine Learning',\n",
       " 'Data Analyst - Core\\xa0Data',\n",
       " 'Senior Staff BI Analyst',\n",
       " 'ESG Data Operations Senior Manager',\n",
       " 'Senior Machine Learning Engineer II, Machine Learning Infrastructure',\n",
       " 'Data Analyst - Contract - 1 day a week',\n",
       " 'ML Engineer',\n",
       " 'Artificial Intelligence Hardware Architect (Senior Hardware Architect)',\n",
       " 'Senior Analytics Engineer - Data Engineer',\n",
       " 'Data Analytics Manager, SPEAR Operations Support & Services (OS2)',\n",
       " 'Senior Software Engineer, Perception, Machine Learning/Computer Vision',\n",
       " 'Machine Learning Engineer - Intelligent Safety',\n",
       " 'Artificial Intelligence Compiler Engineer (Software Engineer)',\n",
       " 'Senior Data Engineer, Marketing Data',\n",
       " 'AI Algorithms - Hardware Codesign Lead (Senior AI Software Engineer)',\n",
       " 'Research Scientist Intern',\n",
       " 'Staff Product Designer, AI/ML',\n",
       " 'Simulation and Data Engineer Inductive Sensors (m/f)',\n",
       " 'Senior Engineer, Data Management Engineering',\n",
       " 'Data Analyst (JIRA & Azure DevOps or HP ALM) - Remote',\n",
       " 'Vice President Data Science, Real World Data Lead',\n",
       " 'Data Engineer - BI Developer',\n",
       " 'Analyst, Data Science',\n",
       " 'Engineering Team Lead, Data Modelling',\n",
       " 'Associate Director, Data Science',\n",
       " 'Cloud/Data Engineer',\n",
       " 'Senior Staff/ Staff Engineer(Python | Spark | Delta Lake | GraphDB | Machine Learning)',\n",
       " 'Team Leader - Data Engineering (REF462H)',\n",
       " 'Data Management Consultant',\n",
       " 'Senior Data Manager, Product Owner',\n",
       " 'Director of Delivery, Data Operations',\n",
       " '(Senior) Machine Learning Engineer \\x96 Video Analysis',\n",
       " 'Student Assistant for Data Management (m/f/d)',\n",
       " 'Data Scientist, Risk',\n",
       " 'Customer Success Support Specialist (Remote Technical Support, Robotics) - U.S.',\n",
       " 'Principal Data Scientist (Seattle or U.S. Remote)',\n",
       " 'Data Engineer - ETL',\n",
       " 'Data Engineer - Internship',\n",
       " 'Market & Business Intelligence Graduate',\n",
       " 'Product Data Analyst',\n",
       " 'Full Stack Engineer for Computer Vision Products',\n",
       " 'Senior Data Scientist (P3186)',\n",
       " 'Senior Machine Learning Engineer, Perception',\n",
       " 'Data Analyst (Internship)',\n",
       " 'Senior Data Engineer (m/f/d)',\n",
       " 'Senior Data Analyst, Engineering Excellence',\n",
       " 'Business Intelligence Analytics Manager',\n",
       " 'Machine Learning Scientist (Intern)',\n",
       " 'Staff Research Engineer (REQ #R273)',\n",
       " 'Senior Machine Learning Scientist',\n",
       " 'Data Scientist, In-car Ads',\n",
       " '[Job-10530] Senior Data Developer, Brazil',\n",
       " 'Deep Learning Field Engineer',\n",
       " 'Data Analyst - Spanish Speaker',\n",
       " 'Data stage ETL',\n",
       " 'Software Engineer, Data Streaming Platform',\n",
       " 'Data Analyst Tech Lead',\n",
       " '[??] ????? ??? (Data Specialist / ???)',\n",
       " 'Knowledge Management Data Specialist',\n",
       " 'Machine Learning Engineer, Fulfillment / Supply Chain',\n",
       " 'Data Engineer - Technical Lead',\n",
       " 'Senior Data engineer (H/F)',\n",
       " 'Analyst, Business Intelligence',\n",
       " 'IT Manager, Advanced Business Intelligence',\n",
       " 'Revenue Operations Data Analyst',\n",
       " 'Data Science Manager',\n",
       " 'Engineering Manager - Core ML & Chatbot',\n",
       " 'Data Engineer (CRYPTO)',\n",
       " 'Associate Data Analyst (Permanent Remote)',\n",
       " 'Economist, Pricing and Causal Inference',\n",
       " 'Customer Data Specialist',\n",
       " 'Senior Manager, Personalization Machine Learning Science',\n",
       " 'Senior Research Analyst- Corporate Research Team',\n",
       " 'Summer Machine Learning Engineer Internship (Skopje, Bitola, Ohrid)',\n",
       " 'Assistant/Associate Professor in Embedded Artificial Intelligence  at Télécom Paris - CDI',\n",
       " 'Software Developer in Data Science Team',\n",
       " 'Machine Learning Systems Engineer',\n",
       " 'Software Engineer - C++ Qt QML Development',\n",
       " 'Data Engineer - Kolkata',\n",
       " 'AI Solution Manager/Senior AI Solution Manager',\n",
       " 'BI Analyst \\x96 Based in Parsippany-Troy Hills, NJ',\n",
       " 'Machine learning trainee',\n",
       " 'Senior Data Analyst, Business Insights - US, Remote',\n",
       " 'Insight Analyst II',\n",
       " 'IN BGSW SystemTester Autonomoriving EXM 2023 (Cloe)',\n",
       " 'Senior Machine Learning Engineer / Senior Python Developer',\n",
       " 'Data Specialist',\n",
       " 'Data Analyst - CRM',\n",
       " 'Junior, Intermediate or Senior Data Analyst',\n",
       " 'QA Data Engineer',\n",
       " 'Head of Business Intelligence',\n",
       " 'Autonomy Software Engineer - Flight Core',\n",
       " 'Data Operations Manager',\n",
       " 'Senior/Lead Data Manager',\n",
       " 'Data Quality Analyst/ Test Analyst',\n",
       " 'Senior Data Analytics Developer',\n",
       " 'Data Science Manager (m/f/d)',\n",
       " 'Lead Data Engineer',\n",
       " 'Senior Data Engineer, Analytics',\n",
       " 'Senior Data Engineer, New Initiatives',\n",
       " 'Data Scientist - Product (U.S. only)',\n",
       " 'Data Analyst (Intern)',\n",
       " 'Data Operations Analyst',\n",
       " 'Associate Data Analytics Manager(CPG)',\n",
       " 'Staff Product Data Analyst',\n",
       " 'Senior Manager Data Engineering - Houston (in office 2 days per week)',\n",
       " 'Database Engineer(Elasticsearch/ OpenSearch)',\n",
       " 'Software Engineer - Machine Learning',\n",
       " 'BI Development Lead - India',\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Job Title\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91691769",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a778a17",
   "metadata": {},
   "source": [
    "# analyse and visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce052f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d298378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39ccb48a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert 129000.040000.0 to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1490\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1490\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[0;32m   1491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1492\u001b[0m         values,\n\u001b[0;32m   1493\u001b[0m         how,\n\u001b[0;32m   1494\u001b[0m         axis\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1495\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m   1496\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1497\u001b[0m     )\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:959\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[1;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups\n\u001b[1;32m--> 959\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cy_op\u001b[38;5;241m.\u001b[39mcython_operation(\n\u001b[0;32m    960\u001b[0m     values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[0;32m    961\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    962\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    963\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    964\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    966\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:657\u001b[0m, in \u001b[0;36mWrappedCythonOp.cython_operation\u001b[1;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ea_wrap_cython_operation(\n\u001b[0;32m    650\u001b[0m         values,\n\u001b[0;32m    651\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    655\u001b[0m     )\n\u001b[1;32m--> 657\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_op_ndim_compat(\n\u001b[0;32m    658\u001b[0m     values,\n\u001b[0;32m    659\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    660\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    661\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[0;32m    662\u001b[0m     mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    664\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:482\u001b[0m, in \u001b[0;36mWrappedCythonOp._cython_op_ndim_compat\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    481\u001b[0m     result_mask \u001b[38;5;241m=\u001b[39m result_mask[\u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[1;32m--> 482\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_cython_op(\n\u001b[0;32m    483\u001b[0m     values2d,\n\u001b[0;32m    484\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    485\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    486\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[0;32m    487\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    488\u001b[0m     result_mask\u001b[38;5;241m=\u001b[39mresult_mask,\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    490\u001b[0m )\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:541\u001b[0m, in \u001b[0;36mWrappedCythonOp._call_cython_op\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    540\u001b[0m out_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_shape(ngroups, values)\n\u001b[1;32m--> 541\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_cython_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_numeric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cython_vals(values)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:173\u001b[0m, in \u001b[0;36mWrappedCythonOp._get_cython_function\u001b[1;34m(cls, kind, how, dtype, is_numeric)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39m__signatures__:\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;66;03m# raise NotImplementedError here rather than TypeError later\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction is not implemented for this dtype: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: function is not implemented for this dtype: [how->mean,dtype->object]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\nanops.py:1692\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1691\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1692\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;66;03m# e.g. \"1+1j\" or \"foo\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '129000.040000.0'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\nanops.py:1696\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1696\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcomplex\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1697\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1698\u001b[0m     \u001b[38;5;66;03m# e.g. \"foo\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate the average salary for each country\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m average_salary_by_country \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcountry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSalary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create choropleth map with a diverging color scale for salary data and average salary as hover data\u001b[39;00m\n\u001b[0;32m      5\u001b[0m fig \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mchoropleth(average_salary_by_country, \n\u001b[0;32m      6\u001b[0m                     locations\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      7\u001b[0m                     color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalary\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m                     custom_data\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Include 'country' as custom data to access it in hover template\u001b[39;00m\n\u001b[0;32m     16\u001b[0m                    )\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1855\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[0;32m   1854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1855\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1856\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1857\u001b[0m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1858\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1507\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1503\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1507\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1508\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   1509\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\internals\\base.py:193\u001b[0m, in \u001b[0;36mSingleDataManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrouped_reduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func):\n\u001b[0;32m    192\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\n\u001b[1;32m--> 193\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[0;32m    196\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_array(res, index)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1503\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1490\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[0;32m   1491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1492\u001b[0m         values,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1496\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1497\u001b[0m     )\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[1;32m-> 1503\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_agg_py_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1457\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1452\u001b[0m     ser \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1454\u001b[0m \u001b[38;5;66;03m# We do not get here with UDFs, so we know that our dtype\u001b[39;00m\n\u001b[0;32m   1455\u001b[0m \u001b[38;5;66;03m#  should always be preserved by the implemented aggregations\u001b[39;00m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;66;03m# TODO: Is this exactly right; see WrappedCythonOp get_result_dtype?\u001b[39;00m\n\u001b[1;32m-> 1457\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, Categorical):\n\u001b[0;32m   1460\u001b[0m     \u001b[38;5;66;03m# Because we only get here with known dtype-preserving\u001b[39;00m\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;66;03m#  reductions, we cast back to Categorical.\u001b[39;00m\n\u001b[0;32m   1462\u001b[0m     \u001b[38;5;66;03m# TODO: if we ever get \"rank\" working, exclude it here.\u001b[39;00m\n\u001b[0;32m   1463\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(values)\u001b[38;5;241m.\u001b[39m_from_sequence(res_values, dtype\u001b[38;5;241m=\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:994\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39m_values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;66;03m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;66;03m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;66;03m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;66;03m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[0;32m    992\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 994\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    996\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:1015\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m   1012\u001b[0m splitter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_splitter(obj, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m-> 1015\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m     res \u001b[38;5;241m=\u001b[39m libreduction\u001b[38;5;241m.\u001b[39mextract_result(res)\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[0;32m   1019\u001b[0m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1857\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[0;32m   1854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1855\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   1856\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 1857\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1858\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   1859\u001b[0m     )\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\generic.py:11556\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11539\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m  11540\u001b[0m     _num_doc,\n\u001b[0;32m  11541\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11554\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11555\u001b[0m ):\n\u001b[1;32m> 11556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\generic.py:11201\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  11195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11196\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11199\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 11201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  11202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  11203\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\generic.py:11158\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11154\u001b[0m     nv\u001b[38;5;241m.\u001b[39mvalidate_stat_func((), kwargs, fname\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m  11156\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 11158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  11159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[0;32m  11160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\series.py:4666\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   4662\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4663\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4664\u001b[0m     )\n\u001b[0;32m   4665\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4666\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\nanops.py:96\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 96\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\nanops.py:158\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    156\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\nanops.py:421\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    419\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 421\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    424\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\nanops.py:727\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    724\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m    726\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m--> 727\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    730\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\nanops.py:1699\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1696\u001b[0m             x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcomplex\u001b[39m(x)\n\u001b[0;32m   1697\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1698\u001b[0m             \u001b[38;5;66;03m# e.g. \"foo\"\u001b[39;00m\n\u001b[1;32m-> 1699\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert 129000.040000.0 to numeric"
     ]
    }
   ],
   "source": [
    "# Calculate the average salary for each country\n",
    "average_salary_by_country = df.groupby('country')['Salary'].mean().reset_index()\n",
    "\n",
    "# Create choropleth map with a diverging color scale for salary data and average salary as hover data\n",
    "fig = px.choropleth(average_salary_by_country, \n",
    "                    locations='country', \n",
    "                    color='Salary', \n",
    "                    locationmode='country names', \n",
    "                    projection='natural earth', \n",
    "                    title='Average Salary by Country',\n",
    "                    color_continuous_scale='RdBu',  # Diverging color scale\n",
    "                    range_color=(df['Salary'].min(), df['Salary'].max()),  # Set the salary range for the color scale\n",
    "                    hover_data={'Salary': True, 'country': False},  # Include 'Salary' as hover data\n",
    "                    labels={'Salary': 'Average Salary', 'color': 'Average Salary'},  # Set hover label\n",
    "                    custom_data=['country']  # Include 'country' as custom data to access it in hover template\n",
    "                   )\n",
    "\n",
    "# Update the hover template to include the average salary for each country\n",
    "hover_template = '<b>%{customdata[0]}</b><br>' + \\\n",
    "                 'Average Salary: %{customdata[1]:,.2f}<extra></extra>'\n",
    "fig.update_traces(hovertemplate=hover_template)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfdc0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0bbad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a custom Nominatim geolocator with a user agent\n",
    "def create_custom_geolocator(user_agent):\n",
    "    return Nominatim(user_agent=user_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d3bafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the 'Salary' column and convert it to numeric\n",
    "def clean_salary(salary):\n",
    "    try:\n",
    "        # Remove commas and asterisks from the salary string\n",
    "        salary = re.sub(r'[,*]', '', salary)\n",
    "        salary = re.sub(r'\\+|\\*', '', salary)\n",
    "        # Convert the salary to numeric\n",
    "        return float(salary)\n",
    "    except:\n",
    "        # Return None for non-numeric or invalid salary values\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ba1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract country name from location string\n",
    "def get_country_name(location, geolocator):\n",
    "    try:\n",
    "        location_info = geolocator.geocode(location, addressdetails=True)\n",
    "        if location_info:\n",
    "            country_name = location_info.raw['address']['country']\n",
    "            return country_name\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6854d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom geolocator with a unique user agent\n",
    "geolocator = create_custom_geolocator('my-custom-application')\n",
    "\n",
    "# Apply the function to 'Location' column and save result to new 'Country' column\n",
    "df['Country'] = df['Location'].apply(lambda x: get_country_name(x, geolocator))\n",
    "\n",
    "# Clean the 'Salary' column and convert it to numeric\n",
    "df['Salary'] = df['Salary'].apply(clean_salary)\n",
    "\n",
    "# Calculate the average salary for each country\n",
    "average_salary_by_country = df.groupby('Country')['Salary'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a25604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create choropleth map with a diverging color scale for salary data and average salary as hover data\n",
    "fig = px.choropleth(average_salary_by_country, \n",
    "                    locations='Country', \n",
    "                    color='Salary', \n",
    "                    locationmode='country names', \n",
    "                    projection='natural earth', \n",
    "                    title='Average Salary by Country',\n",
    "                    color_continuous_scale='RdBu',  # Diverging color scale\n",
    "                    range_color=(df['Salary'].min(), df['Salary'].max()),  # Set the salary range for the color scale\n",
    "                    hover_data={'Salary': True, 'Country': False},  # Include 'Salary' as hover data\n",
    "                    labels={'Salary': 'Average Salary', 'color': 'Average Salary'},  # Set hover label\n",
    "                    custom_data=['Country']  # Include 'Country' as custom data to access it in hover template\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0970fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the hover template to include the average salary for each country\n",
    "hover_template = '<b>%{customdata[0]}</b><br>' + \\\n",
    "                 'Average Salary: %{customdata[1]:,.2f}<extra></extra>'\n",
    "fig.update_traces(hovertemplate=hover_template)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1232cd78",
   "metadata": {},
   "source": [
    "## map for each job title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5025bbfd",
   "metadata": {},
   "source": [
    "## map for each level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766e78e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101bb788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067e0e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dff8068b",
   "metadata": {},
   "source": [
    "## Quelles sont les entreprises les plus actives dans le recrutement en IA, Data Science et Big Data ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11711a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0638821",
   "metadata": {},
   "source": [
    "## Quels sont les titres de poste les plus courants dans ces domaines ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da0055b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50d50653",
   "metadata": {},
   "source": [
    "## Quels sont les lieux géographiques les plus demandés pour les opportunités d'emploi en IA, Data Science et Big Data ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e7a845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "734e0e08",
   "metadata": {},
   "source": [
    "## Quels types d'emplois (Full Time, Internship, etc.) sont les plus fréquents pour ces domaines ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb3a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ced8cb7",
   "metadata": {},
   "source": [
    "## Quel est le niveau d'expérience le plus recherché dans les offres d'emploi en IA, Data Science et Big Data ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d6ef99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43fe4a55",
   "metadata": {},
   "source": [
    "## Quels sont les niveaux de salaire typiques pour différents postes et niveaux d'expérience ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd1856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "088a9e19",
   "metadata": {},
   "source": [
    "## Quelles sont les compétences les plus demandées dans les offres d'emploi en IA, Data Science et Big Data ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af9f95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e16e28e4",
   "metadata": {},
   "source": [
    "## Quels avantages ou facilités sont souvent proposés aux employés dans ces domaines ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751c78c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcd02c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb20ec55",
   "metadata": {},
   "source": [
    "## Comparer les opportunités d'emploi dans l'IA, la Data Science et le Big Data pour trouver des similitudes et des différences significatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2430f8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f744592",
   "metadata": {},
   "source": [
    "## Étudier la relation entre les compétences demandées et les niveaux de salaire offerts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2762cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3928c34e",
   "metadata": {},
   "source": [
    "## Examiner comment les différentes entreprises se positionnent sur le marché de l'emploi dans ces domaines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6d0fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df41f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0390990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "509dcd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Company, Job Title, Location, Job Type, Experience level, Salary, Requirment of the company , Facilities]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"Company\"]=='Western Sahara']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad361f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"country\"]=='United States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d037257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original \"Location\" column as it's no longer needed\n",
    "df.drop('Location', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5f9750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the 'Salary' column to 'Salary * 1000'\n",
    "df.rename(columns={'Salary': 'Salary en $'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eecbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data to the CSV file\n",
    "df.to_csv('updated_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52568dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame to an Excel file\n",
    "df.to_excel('updated_dataset.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
